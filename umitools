#!/usr/bin/env python
# encoding: utf-8
"""
Tools to handle reads sequenced with unique molecular identifiers (UMIs).
"""
import sys
from re import findall
from pysam import Samfile
from toolshed import nopen
from collections import Counter
from itertools import islice, izip

# Until I separate out the tests, OS X needs this:
# http://goo.gl/jNOGp
import os
os.environ['TERM'] = 'linux'

IUPAC = {"A":"A","T":"T","C":"C","G":"G","R":"GA","Y":"TC",
         "M":"AC","K":"GT","S":"GC","W":"AT","H":"ACT",
         "B":"GTC","V":"GCA","D":"GAT","N":"GATC"}

def decode(x):
    """not accounting for other scoring
    
    >>> decode("4")
    19
    >>> decode(";")
    26
    """
    return ord(x) - 33

def average(quals):
    """
    >>> average("4578;;77;;H@GFF>DFFFFFEEE")
    30.84...
    >>> average("/==96996<FGCHHHGGGFFE=EDFFFEEB")
    32.53...
    """
    vals = map(decode, quals)
    return sum(vals)/float(len(quals))

def write_reads(bam, reads, cap):
    """writes the read, but also verifies UMI saturation cap."""
    pos = 0
    neg = 0
    for umi, read in reads.iteritems():
        if umi.endswith("neg"): neg += 1
        if umi.endswith("pos"): pos += 1
        bam.write(read)
    assert pos <= cap
    assert neg <= cap

def total_possible(umi):
    """total possible UMI combinations.
    >>> total_possible("NNNNNV")
    3072
    >>> total_possible("NNNNNR")
    2048
    """
    return reduce(lambda x, y: x * y, [len(IUPAC[n]) for n in umi])

def umi_from_name(name):
    """extract the UMI sequence from the read name.
    >>> umi_from_name("cluster_1017333:UMI_GCCGCA")
    'GCCGCA'
    """
    return findall(r'UMI_([\w]*)', name)[0].strip()

def add_strand(umi, reverse):
    """add strand info onto UMI, allowing pos and neg strand to saturate UMI.
    >>> add_strand("GCCGCA", True)
    'GCCGCAneg'
    >>> add_strand("GCCGCA", False)
    'GCCGCApos'
    """
    return "%sneg" % umi if reverse else "%spos" % umi

def process_bam(args):
    """removes duplicate reads characterized by their UMI at any given start
    location.
    """
    possible = total_possible(args.umi)
    with Samfile(args.abam, 'rb') as sam,\
            Samfile(args.bbam, 'wb', template=sam) as bam:
        unique_reads = {}
        pos = filtered = seen = 0
        for read in sam.fetch():
            seen += 1
            umi = add_strand(umi_from_name(read.qname), read.is_reverse)
            if read.pos == pos:
                try:
                    # keep the read with higher average quality
                    if average(unique_reads[umi].qqual) < average(read.qqual):
                        unique_reads[umi] = read
                    filtered += 1
                except KeyError:
                    unique_reads[umi] = read
            else:
                write_reads(bam, unique_reads, possible)
                unique_reads = {umi:read}
                pos = read.pos
        write_reads(bam, unique_reads, possible)
        if args.verbose:
            print >>sys.stderr, "Input Sequences:     %d" % seen
            print >>sys.stderr, "Sequences Removed:   %d" % filtered
            print >>sys.stderr, "Remaining Sequences: %d" % (seen - filtered)

def read_fastq(fh):
    """fastq parser that returns name, seq, and qual."""
    while True:
        values = list(islice(fh, 4))
        if len(values) == 4:
            id1, seq, id2, qual = values
        elif len(values) == 0:
            raise StopIteration
        else:
            raise EOFError("unexpected end of file")
        assert id1.startswith('@'),\
                ">> Fastq out of sync at read:\n%s\n" % id1
        assert id2.startswith('+'),\
                ">> Fastq out of sync at read:\n%s\n" % id1
        assert len(seq) == len(qual),\
                ">> Sequence and Quality are not the same length \
                for read:\n%s\n" % id1
        yield id1[1:-1], seq[:-1], qual[:-1]

def valid_umi(iupac, umi):
    """parse UMI sequence to validate against IUPAC sequence.
    >>> valid_umi("NNNV", "ACGT")
    False
    >>> valid_umi("NNNV", "ACGG")
    True
    """
    for code, base in izip(iupac, umi):
        try:
            if not base in IUPAC[code]:
                return False
        except KeyError:
            return False
    return True

def create_record(name, seq, qual, iupac_umi, length, end):
    """
    >>> create_record("cluster_455",\
            "GGGGGAGCCACGAGGTGTGTTTTATTTTCATTATTC",\
            "C===>=B=@:<;4A;8=9?6EEC0?DDA72B@3EB4",\
            "NNNNNV", 6, "5")
    '@cluster_455:UMI_GGGGGA\\nGCCACGAGGTGTGTTTT\
ATTTTCATTATTC\\n+\\nB=@:<;4A;8=9?6EEC0?DDA72B@3EB4'
    >>> create_record("cluster_455",\
            "GGGGGTGCCACGATTCATTATTC",\
            "C===>=B=@:0?DDA72B@3EB4",\
            "NNNNNV", 6, "5")
    (False, 'GGGGGT')
    >>> create_record("cluster_455",\
            "GGGGGAGCCACGAGGTGTGTTTTATTTTCATTATTC",\
            "C===>=B=@:<;4A;8=9?6EEC0?DDA72B@3EB4",\
            "NNNNNV", 6, "3")
    '@cluster_455:UMI_TTATTC\\nGGGGGAGCCACGAGGTG\
TGTTTTATTTTCA\\n+\\nC===>=B=@:<;4A;8=9?6EEC0?DDA72'
    """
    if end == "5":
        umi = seq[:length]
        seq = seq[length:]
        qual = qual[length:]
    else:
        umi = seq[-length:]
        seq = seq[:-length]
        qual = qual[:-length]    
    if not valid_umi(iupac_umi, umi): return False, umi
    return "@%s:UMI_%s\n%s\n+\n%s" % (name, umi, seq, qual)

def process_fastq(args):
    """for every valid umi, trim while incorporating into read name."""
    umi_stats = Counter()
    umi_length = len(args.umi)
    with nopen(args.fastq) as fh:
        for name, seq, qual in read_fastq(fh):
            record = create_record(name, seq, qual, args.umi, umi_length, args.end)
            if record[0]:
                print record
            else:
                record, umi = record
                umi_stats.update([umi])
    if args.verbose:
        print >>sys.stderr, "Invalid UMI Total:   %d" % sum(umi_stats.values())
        print >>sys.stderr, "Unique UMIs Removed: %d" % len(list(umi_stats))
        print >>sys.stderr, "Top %d Invalid UMIs:" % args.top
        for umi, val in umi_stats.most_common(args.top):
            print >>sys.stderr, "\t".join([umi, str(val)])

def main(args):
    args.func(args)

if __name__ == "__main__":
    import argparse
    import doctest
    p = argparse.ArgumentParser(description=__doc__,
            formatter_class=argparse.RawDescriptionHelpFormatter)
    subp = p.add_subparsers(help='commands')
    # fastq processing
    fastq = subp.add_parser('trim', description="Trims the UMI sequence from \
            the read, incorporating the unique sequence in the read name \
            facilitating filtering of the alignments.",
            help="trim UMI and incorporate sequence into read name")
    fastq.add_argument('fastq', metavar='FASTQ',
            help='reads with untrimmed UMI')
    fastq.add_argument('umi', metavar='UMI',
            help='IUPAC UMI sequence, e.g. NNNNNV')
    fastq.add_argument('--end', choices=['5', '3'], default="5", 
            help="UMI location on the read [%(default)s]")
    fastq.add_argument('--verbose', action='store_true',
            help="print UMI stats to stderr [%(default)s]")
    fastq.add_argument('--top', type=int, default=10,
            help="when verbose, print this many of the top filtered \
            UMI sequences [%(default)s]")
    fastq.set_defaults(func=process_fastq)
    # bam processing
    bam = subp.add_parser('rmdup', description="Removes duplicate reads, that \
            were previously characterized by their UMI, at any given start \
            location.",
            help="remove duplicate UMI entries from all start positions")
    bam.add_argument('abam', metavar='INPUT_BAM',
            help='bam with UMI in read name')
    bam.add_argument('bbam', metavar='OUTPUT_BAM',
            help='non-duplicate UMIs at any given start position')
    bam.add_argument('umi', metavar='UMI',
            help='IUPAC sequence of the UMI, e.g. NNNNNV')
    bam.add_argument('--verbose', action='store_true',
            help="print rmdup stats [%(default)s]")
    bam.set_defaults(func=process_bam)
    if doctest.testmod(optionflags=doctest.ELLIPSIS |\
                                   doctest.NORMALIZE_WHITESPACE).failed == 0:
        main(p.parse_args())