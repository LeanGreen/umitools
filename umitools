#!/usr/bin/env python
# encoding: utf-8
"""
Tools to handle reads sequenced with unique molecular identifiers (UMIs).

TODO:
verify that no position has more counts than allowable by UMI
"""
import sys
from re import findall
from pysam import Samfile
from toolshed import nopen
from collections import Counter
from itertools import islice, izip

# until i separate out the tests, osx needs this
# http://goo.gl/jNOGp
import os
os.environ['TERM'] = 'linux'

def decode(x):
    """not accounting for other scoring
    
    >>> decode("4")
    19
    >>> decode(";")
    26
    """
    return ord(x) - 33

def average(quals):
    """
    >>> average("4578;;77;;H@GFF>DFFFFFEEE")
    30.84...
    >>> average("/==96996<FGCHHHGGGFFE=EDFFFEEB")
    32.53...
    """
    vals = map(decode, quals)
    return sum(vals)/float(len(quals))

def process_bam(args):
    """removes duplicate reads characterized by their UMI at any given start 
    location.
    """
    with Samfile(args.abam, 'rb') as sam,\
            Samfile(args.bbam, 'wb', template=sam) as bam:
        unique_reads = {}
        pos = 0
        for read in sam.fetch():
            umi = findall(r'UMI_([\w]*)', read.qname)[0].strip()
            # strand info onto umi allowing pos and neg strand to saturate UMI
            umi = "%sneg" % umi if read.is_reverse else "%spos" % umi
            # same start coord
            if read.pos == pos:
                try:
                    # keep the read with higher average quality
                    if average(unique_reads[umi].qqual) < average(read.qqual):
                        unique_reads[umi] = read
                except KeyError:
                    unique_reads[umi] = read
            # new start coord
            else:
                [bam.write(r) for r in unique_reads.itervalues()]
                unique_reads = {}
                unique_reads[umi] = read
                pos = read.pos
        [bam.write(r) for r in unique_reads.itervalues()]

def read_fastq(fh):
    """fastq parser that returns name, seq, and qual."""
    while True:
        values = list(islice(fh, 4))
        if len(values) == 4:
            id1, seq, id2, qual = values
        elif len(values) == 0:
            raise StopIteration
        else:
            raise EOFError("unexpected end of file")
        assert id1.startswith('@'),\
                ">> Fastq out of sync at read:\n%s\n" % id1
        assert id2.startswith('+'),\
                ">> Fastq out of sync at read:\n%s\n" % id1
        assert len(seq) == len(qual),\
                ">> Sequence and Quality are not the same length \
                for read:\n%s\n" % id1
        yield id1[1:-1], seq[:-1], qual[:-1]

def valid_umi(iupac, umi):
    """parse UMI sequence to validate against IUPAC sequence.
    
    >>> valid_umi("NNNV", "ACGT")
    False

    >>> valid_umi("NNNV", "ACGG")
    True
    """
    IUPAC_definitions = {"A":"A","T":"T","C":"C","G":"G","R":"GA","Y":"TC",
                            "M":"AC","K":"GT","S":"GC","W":"AT","H":"ACT",
                            "B":"GTC","V":"GCA","D":"GAT","N":"GATC"}
    for code, base in izip(iupac, umi):
        try:
            if not base in IUPAC_definitions[code]:
                return False
        except KeyError:
            return False
    return True

def create_record(name, seq, qual, iupac_umi, length, end):
    """
    # UMI on the 5' end
    >>> create_record("cluster_455",\
            "GGGGGAGCCACGAGGTGTGTTTTATTTTCATTATTC",\
            "C===>=B=@:<;4A;8=9?6EEC0?DDA72B@3EB4",\
            "NNNNNV", 6, "5")
    '@cluster_455:UMI_GGGGGA\\nGCCACGAGGTGTGTTTTATTTTCATTATTC\\n+\\nB=@:<;4A;8=9?6EEC0?DDA72B@3EB4'

    # invalid UMI
    >>> create_record("cluster_455",\
            "GGGGGTGCCACGATTCATTATTC",\
            "C===>=B=@:0?DDA72B@3EB4",\
            "NNNNNV", 6, "5")
    (False, 'GGGGGT')

    # UMI on the 3' end
    >>> create_record("cluster_455",\
            "GGGGGAGCCACGAGGTGTGTTTTATTTTCATTATTC",\
            "C===>=B=@:<;4A;8=9?6EEC0?DDA72B@3EB4",\
            "NNNNNV", 6, "3")
    '@cluster_455:UMI_TTATTC\\nGGGGGAGCCACGAGGTGTGTTTTATTTTCA\\n+\\nC===>=B=@:<;4A;8=9?6EEC0?DDA72'
    """
    if end == "5":
        umi = seq[:length]
        # validate
        if valid_umi(iupac_umi, umi):
            # make record and return
            return "@%s:UMI_%s\n%s\n+\n%s" % \
                        (name, umi, seq[length:], qual[length:])
        else:
            return False, umi
    else: # 3' end
        umi = seq[-length:]
        # validate
        if valid_umi(iupac_umi, umi):
            # make record and return
            return "@%s:UMI_%s\n%s\n+\n%s" % \
                        (name, umi, seq[:-length], qual[:-length])
        else:
            return False, umi

def process_fastq(args):
    """reads in fastq with UMI still in the sequence to verify the UMI as valid;
    trim the UMI; and incorporate the UMI sequence into read name.
    """
    umi_stats = Counter()
    umi_length = len(args.umi)
    with nopen(args.fastq) as fastq:
        for name, seq, qual in read_fastq(fastq):
            record = create_record(name, seq, qual, args.umi, umi_length, args.end)
            if record[0]:
                print record
            else:
                record, umi = record
                umi_stats.update([umi])
    if args.verbose:
        print >> sys.stderr, "Invalid UMI Total:   %d" % sum(umi_stats.values())
        print >> sys.stderr, "Unique UMIs Removed: %d" % len(list(umi_stats))
        # could option this out
        print >> sys.stderr, "Top 10 Invalid UMIs:"
        for umi, val in umi_stats.most_common(10):
            print >> sys.stderr, "\t".join([umi, str(val)])

def main(args):
    args.func(args)

if __name__ == "__main__":
    import argparse
    import doctest
    p = argparse.ArgumentParser(description=__doc__,
            formatter_class=argparse.RawDescriptionHelpFormatter)
    subp = p.add_subparsers(help='commands')
    # fastq processing
    fastq = subp.add_parser('trim', 
            help="trim UMI and incorporate sequence into read name")
    fastq.add_argument('fastq', metavar='FASTQ',
            help='reads with untrimmed UMI')
    fastq.add_argument('umi', metavar='UMI',
            help='IUPAC UMI sequence, e.g. NNNNNV')
    fastq.add_argument('--end', choices=['5', '3'], default="5", 
            help="UMI location on the read [ %(default)s ]")
    fastq.add_argument('--verbose', action='store_true',
            help="print UMI stats to stderr [ %(default)s ]")
    fastq.set_defaults(func=process_fastq)
    # bam processing
    bam = subp.add_parser('rmdup', help="remove duplicate UMI \
            entries from all start positions")
    bam.add_argument('abam', metavar='INPUT_BAM',
            help='bam with UMI in read name')
    bam.add_argument('bbam', metavar='OUTPUT_BAM',
            help='non-duplicate UMIs at any given start position')
    bam.set_defaults(func=process_bam)
    if doctest.testmod(optionflags=doctest.ELLIPSIS |\
                                   doctest.NORMALIZE_WHITESPACE).failed == 0:
        main(p.parse_args())